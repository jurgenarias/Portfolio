{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB       # Naive Bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['post']     # Setting the X and y\n",
    "y = data['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.505814\n",
       "1.0    0.494186\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)   # Cheking base line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline with Multinomial NB and Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 14.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for cv: 0.9256774511414025\n",
      "Best Parameters: {'cvect__max_features': 200000, 'cvect__ngram_range': (1, 2), 'cvect__stop_words': 'english'}\n",
      "Train score: 0.9415257020857284\n",
      "Test score: 0.9259496477311918\n"
     ]
    }
   ],
   "source": [
    "pipeCVnb = Pipeline([           # Using pipeline with CountVectorizer and MultinomialNB\n",
    "    ('cvect', CountVectorizer()),\n",
    "    ('Mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeCVnb_params = {         # Setting the parameters \n",
    "               'cvect__max_features': [150_000, 200_000], \n",
    "               'cvect__stop_words': [None, 'english'],\n",
    "               'cvect__ngram_range': [(1,3),(1,2)] \n",
    "              }\n",
    "\n",
    "# Using the GridSearchCV to find best parameters\n",
    "gsCVnb = GridSearchCV(pipeCVnb, # What is the model we want to fit?\n",
    "                  pipeCVnb_params, # What is the dictionary of hyperparameters?\n",
    "                  cv=3, verbose=1)\n",
    "\n",
    "gsCVnb.fit(X_train, y_train)   # Fitting the train data\n",
    "\n",
    "print(f'Best Score for cv: {gsCVnb.best_score_}')   # Printing best score for CV\n",
    "\n",
    "print(f'Best Parameters: {gsCVnb.best_params_}') # Checking best parameters for CV\n",
    "\n",
    "gsCVnb_model = gsCVnb.best_estimator_     # Setting our best model\n",
    "\n",
    "print(f'Train score: {gsCVnb_model.score(X_train, y_train)}')    # Scoring train data on our best model \n",
    "\n",
    "print(f'Test score: {gsCVnb_model.score(X_test, y_test)}')    # Scoring test data on our best model \n",
    "\n",
    "os.system(\"printf '\\a'\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get report on grid search results\n",
    "best_model_params = pd.DataFrame(gsCVnb.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params.to_csv('best_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_cvect__max_features</th>\n",
       "      <th>param_cvect__ngram_range</th>\n",
       "      <th>param_cvect__stop_words</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>200000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.925677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>150000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.925579</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>150000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.925497</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>200000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.925439</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>200000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.910076</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>150000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.909739</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>200000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.906339</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>150000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.905494</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_cvect__max_features param_cvect__ngram_range param_cvect__stop_words  \\\n",
       "7                    200000                   (1, 2)                 english   \n",
       "3                    150000                   (1, 2)                 english   \n",
       "1                    150000                   (1, 3)                 english   \n",
       "5                    200000                   (1, 3)                 english   \n",
       "6                    200000                   (1, 2)                    None   \n",
       "2                    150000                   (1, 2)                    None   \n",
       "4                    200000                   (1, 3)                    None   \n",
       "0                    150000                   (1, 3)                    None   \n",
       "\n",
       "   mean_test_score  rank_test_score  \n",
       "7         0.925677                1  \n",
       "3         0.925579                2  \n",
       "1         0.925497                3  \n",
       "5         0.925439                4  \n",
       "6         0.910076                5  \n",
       "2         0.909739                6  \n",
       "4         0.906339                7  \n",
       "0         0.905494                8  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_params.drop(columns=['mean_fit_time','std_fit_time','mean_score_time','std_score_time',\n",
    "                               'params', 'split0_test_score','split1_test_score', 'split2_test_score',\n",
    "                               'std_test_score']).sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline with Multinomial NB and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   43.6s remaining:   43.6s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for cv: 0.9183199211693217\n",
      "Best Parameters: {'tfi__max_features': 75000, 'tfi__ngram_range': (1, 2), 'tfi__stop_words': 'english'}\n",
      "Train score: 0.9311299063885695\n",
      "Test score: 0.9179435384539587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeTIFInb = Pipeline([       # Using pipeline with Tifidifi and MultinomialNB\n",
    "    ('tfi', TfidfVectorizer(lowercase=False)),\n",
    "    ('Mnb', MultinomialNB())\n",
    "])    \n",
    "\n",
    "pipeTIFInb_params = {       # Setting the parameters\n",
    "               'tfi__max_features': [75_000],\n",
    "               'tfi__stop_words': ['english'],\n",
    "               'tfi__ngram_range': [(1,3),(1,2)]\n",
    "              }\n",
    "\n",
    "gsTIFInb = GridSearchCV(pipeTIFInb, # What is the model we want to fit?\n",
    "                  pipeTIFInb_params, # What is the dictionary of hyperparameters?\n",
    "                  cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "gsTIFInb.fit(X_train, y_train)   # Fitting the train data\n",
    "\n",
    "print(f'Best Score for cv: {gsTIFInb.best_score_}')   # Printing best score for CV\n",
    "\n",
    "print(f'Best Parameters: {gsTIFInb.best_params_}') # Checking best parameters for CV\n",
    "\n",
    "gsTIFInb_model = gsTIFInb.best_estimator_     # Setting our best model\n",
    "\n",
    "print(f'Train score: {gsTIFInb_model.score(X_train, y_train)}')    # Scoring train data on our best model \n",
    "\n",
    "print(f'Test score: {gsTIFInb_model.score(X_test, y_test)}')    # Scoring test data on our best model \n",
    "\n",
    "os.system(\"printf '\\a'\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_tfi__max_features</th>\n",
       "      <th>param_tfi__ngram_range</th>\n",
       "      <th>param_tfi__stop_words</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>67.051101</td>\n",
       "      <td>0.046291</td>\n",
       "      <td>5.947995</td>\n",
       "      <td>0.059553</td>\n",
       "      <td>75000</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>english</td>\n",
       "      <td>{'tfi__max_features': 75000, 'tfi__ngram_range...</td>\n",
       "      <td>0.916465</td>\n",
       "      <td>0.917081</td>\n",
       "      <td>0.918752</td>\n",
       "      <td>0.917433</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33.522923</td>\n",
       "      <td>0.219780</td>\n",
       "      <td>6.591595</td>\n",
       "      <td>0.101660</td>\n",
       "      <td>75000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>{'tfi__max_features': 75000, 'tfi__ngram_range...</td>\n",
       "      <td>0.917402</td>\n",
       "      <td>0.917993</td>\n",
       "      <td>0.919565</td>\n",
       "      <td>0.918320</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      67.051101      0.046291         5.947995        0.059553   \n",
       "1      33.522923      0.219780         6.591595        0.101660   \n",
       "\n",
       "  param_tfi__max_features param_tfi__ngram_range param_tfi__stop_words  \\\n",
       "0                   75000                 (1, 3)               english   \n",
       "1                   75000                 (1, 2)               english   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'tfi__max_features': 75000, 'tfi__ngram_range...           0.916465   \n",
       "1  {'tfi__max_features': 75000, 'tfi__ngram_range...           0.917402   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.917081           0.918752         0.917433        0.000966   \n",
       "1           0.917993           0.919565         0.918320        0.000913   \n",
       "\n",
       "   rank_test_score  \n",
       "0                2  \n",
       "1                1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get report on grid search results\n",
    "pd.DataFrame(gsTIFInb.cv_results_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline with Random Forest and Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for cv: 0.9009361143044835\n",
      "Best Parameters: {'cvect__max_features': 50000, 'cvect__ngram_range': (1, 1), 'cvect__stop_words': 'english'}\n",
      "Train score: 0.9944818525209393\n",
      "Test score: 0.9043701039562497\n"
     ]
    }
   ],
   "source": [
    "pipeCVrf = Pipeline([           # Using pipeline with CountVectorizer and MultinomialNB\n",
    "    ('cvect', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeCVrf_params = {         # Setting the parameters \n",
    "               'cvect__max_features': [50_000], \n",
    "               'cvect__stop_words': ['english'],\n",
    "               'cvect__ngram_range': [(1,1)], \n",
    "              }\n",
    "\n",
    "# Using the GridSearchCV to find best parameters\n",
    "gsCVrf = GridSearchCV(pipeCVrf, # What is the model we want to fit?\n",
    "                  pipeCVrf_params, # What is the dictionary of hyperparameters?\n",
    "                  cv=3, n_jobs=-1)\n",
    "\n",
    "gsCVrf.fit(X_train, y_train)   # Fitting the train data\n",
    "\n",
    "print(f'Best Score for cv: {gsCVrf.best_score_}')   # Printing best score for CV\n",
    "\n",
    "print(f'Best Parameters: {gsCVrf.best_params_}') # Checking best parameters for CV\n",
    "\n",
    "gsCVrf_model = gsCVrf.best_estimator_     # Setting our best model\n",
    "\n",
    "print(f'Train score: {gsCVrf_model.score(X_train, y_train)}')    # Scoring train data on our best model \n",
    "\n",
    "print(f'Test score: {gsCVrf_model.score(X_test, y_test)}')    # Scoring test data on our best model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('say -v Samantha Your code is done running');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline with Random Forest and Tfid Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for cv: 0.9170471341763836\n",
      "Best Parameters: {'tfi__max_features': 50000, 'tfi__ngram_range': (1, 2), 'tfi__stop_words': 'english'}\n",
      "Train score: 0.9280916406634916\n",
      "Test score: 0.9170567078878652\n"
     ]
    }
   ],
   "source": [
    "pipeTIFIrf = Pipeline([           # Using pipeline with CountVectorizer and MultinomialNB\n",
    "    ('tfi', TfidfVectorizer(lowercase=False)),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeTIFIrf_params = {         # Setting the parameters \n",
    "               'tfi__max_features': [50_000], \n",
    "               'tfi__stop_words': ['english'],\n",
    "               'tfi__ngram_range': [(1,1)], \n",
    "              }\n",
    "\n",
    "# Using the GridSearchCV to find best parameters\n",
    "gsTIFIrf = GridSearchCV(pipeTIFIrf, # What is the model we want to fit?\n",
    "                  pipeTIFIrf_params, # What is the dictionary of hyperparameters?\n",
    "                  cv=3, n_jobs=-1)\n",
    "\n",
    "gsTIFIrf.fit(X_train, y_train)   # Fitting the train data\n",
    "\n",
    "print(f'Best Score for cv: {gsTIFInb.best_score_}')   # Printing best score for CV\n",
    "\n",
    "print(f'Best Parameters: {gsTIFInb.best_params_}') # Checking best parameters for CV\n",
    "\n",
    "gsTIFInb_model = gsTIFInb.best_estimator_     # Setting our best model\n",
    "\n",
    "print(f'Train score: {gsTIFInb_model.score(X_train, y_train)}')    # Scoring train data on our best model \n",
    "\n",
    "print(f'Test score: {gsTIFInb_model.score(X_test, y_test)}')    # Scoring test data on our best model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline with Extra Trees and Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for cv: 0.8975201182460174\n",
      "Best Parameters: {'cvect__max_features': 50000, 'cvect__ngram_range': (1, 1), 'cvect__stop_words': 'english'}\n",
      "Train score: 0.998127771391033\n",
      "Test score: 0.8979405823520717\n"
     ]
    }
   ],
   "source": [
    "pipeCVet = Pipeline([           # Using pipeline with CountVectorizer and MultinomialNB\n",
    "    ('cvect', CountVectorizer()),\n",
    "    ('et', ExtraTreesClassifier())\n",
    "])\n",
    "\n",
    "pipeCVet_params = {         # Setting the parameters \n",
    "               'cvect__max_features': [50_000], \n",
    "               'cvect__stop_words': ['english'],\n",
    "               'cvect__ngram_range': [(1,1)], \n",
    "              }\n",
    "\n",
    "# Using the GridSearchCV to find best parameters\n",
    "gsCVet = GridSearchCV(pipeCVet, # What is the model we want to fit?\n",
    "                  pipeCVet_params, # What is the dictionary of hyperparameters?\n",
    "                  cv=3, n_jobs=-1)\n",
    "\n",
    "gsCVet.fit(X_train, y_train)   # Fitting the train data\n",
    "\n",
    "print(f'Best Score for cv: {gsCVet.best_score_}')   # Printing best score for CV\n",
    "\n",
    "print(f'Best Parameters: {gsCVet.best_params_}') # Checking best parameters for CV\n",
    "\n",
    "gsCVet_model = gsCVet.best_estimator_     # Setting our best model\n",
    "\n",
    "print(f'Train score: {gsCVet_model.score(X_train, y_train)}')    # Scoring train data on our best model \n",
    "\n",
    "print(f'Test score: {gsCVet_model.score(X_test, y_test)}')    # Scoring test data on our best model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline with Extra Trees and Tfid Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for cv: 0.9027754967975037\n",
      "Best Parameters: {'tfi__max_features': 50000, 'tfi__ngram_range': (1, 1), 'tfi__stop_words': 'english'}\n",
      "Train score: 0.9984233864345541\n",
      "Test score: 0.9058481548997389\n"
     ]
    }
   ],
   "source": [
    "pipeTIFIet = Pipeline([           # Using pipeline with CountVectorizer and MultinomialNB\n",
    "    ('tfi', TfidfVectorizer(lowercase=False)),\n",
    "    ('et', ExtraTreesClassifier())\n",
    "])\n",
    "\n",
    "pipeTIFIet_params = {         # Setting the parameters \n",
    "               'tfi__max_features': [50_000], \n",
    "               'tfi__stop_words': ['english'],\n",
    "               'tfi__ngram_range': [(1,1)], \n",
    "              }\n",
    "\n",
    "# Using the GridSearchCV to find best parameters\n",
    "gsTIFIet = GridSearchCV(pipeTIFIet, # What is the model we want to fit?\n",
    "                  pipeTIFIet_params, # What is the dictionary of hyperparameters?\n",
    "                  cv=3, n_jobs=-1)\n",
    "\n",
    "gsTIFIet.fit(X_train, y_train)   # Fitting the train data\n",
    "\n",
    "print(f'Best Score for cv: {gsTIFIet.best_score_}')   # Printing best score for CV\n",
    "\n",
    "print(f'Best Parameters: {gsTIFIet.best_params_}') # Checking best parameters for CV\n",
    "\n",
    "gsTIFIet_model = gsTIFIet.best_estimator_     # Setting our best model\n",
    "\n",
    "print(f'Train score: {gsTIFIet_model.score(X_train, y_train)}')    # Scoring train data on our best model \n",
    "\n",
    "print(f'Test score: {gsTIFIet_model.score(X_test, y_test)}')    # Scoring test data on our best model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline with Logistic Regression and Tfid Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for cv: 0.9366069962226967\n",
      "Best Parameters: {'tfi__max_features': 75000, 'tfi__ngram_range': (1, 2), 'tfi__stop_words': 'english'}\n",
      "Train score: 0.9564214156675973\n",
      "Test score: 0.9388333251219392\n"
     ]
    }
   ],
   "source": [
    "pipeTIFIlr = Pipeline([           # Using pipeline with TfidVectorizer and Logistic Regression\n",
    "    ('tfi', TfidfVectorizer(lowercase=False)),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeTIFIlr_params = {         # Setting the parameters \n",
    "               'tfi__max_features': [50_000, 75_000, 100_000], \n",
    "               'tfi__stop_words': [None, 'english'],\n",
    "               'tfi__ngram_range': [(1,1),(1,2)]\n",
    "              }\n",
    "\n",
    "# Using the GridSearchCV to find best parameters\n",
    "gsTIFIlr = GridSearchCV(pipeTIFIlr, # What is the model we want to fit?\n",
    "                  pipeTIFIlr_params, # What is the dictionary of hyperparameters?\n",
    "                  cv=3, n_jobs=-1)\n",
    "\n",
    "gsTIFIlr.fit(X_train, y_train)   # Fitting the train data\n",
    "\n",
    "print(f'Best Score for cv: {gsTIFIlr.best_score_}')   # Printing best score for CV\n",
    "\n",
    "print(f'Best Parameters: {gsTIFIlr.best_params_}') # Checking best parameters for CV\n",
    "\n",
    "gsTIFIlr_model = gsTIFIlr.best_estimator_     # Setting our best model\n",
    "\n",
    "print(f'Train score: {gsTIFIlr_model.score(X_train, y_train)}')    # Scoring train data on our best model \n",
    "\n",
    "print(f'Test score: {gsTIFIlr_model.score(X_test, y_test)}')    # Scoring test data on our best model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get report on grid search results\n",
    "best_model_params = pd.DataFrame(gsTIFIlr.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_tfi__max_features</th>\n",
       "      <th>param_tfi__ngram_range</th>\n",
       "      <th>param_tfi__stop_words</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.139083</td>\n",
       "      <td>0.176619</td>\n",
       "      <td>8.409898</td>\n",
       "      <td>0.060415</td>\n",
       "      <td>50000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfi__max_features': 50000, 'tfi__ngram_range...</td>\n",
       "      <td>0.935508</td>\n",
       "      <td>0.934646</td>\n",
       "      <td>0.934864</td>\n",
       "      <td>0.935006</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18.161496</td>\n",
       "      <td>0.197442</td>\n",
       "      <td>7.322226</td>\n",
       "      <td>0.156035</td>\n",
       "      <td>50000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>{'tfi__max_features': 50000, 'tfi__ngram_range...</td>\n",
       "      <td>0.936542</td>\n",
       "      <td>0.936567</td>\n",
       "      <td>0.935603</td>\n",
       "      <td>0.936237</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>63.464119</td>\n",
       "      <td>0.886825</td>\n",
       "      <td>15.866807</td>\n",
       "      <td>0.696200</td>\n",
       "      <td>50000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfi__max_features': 50000, 'tfi__ngram_range...</td>\n",
       "      <td>0.933537</td>\n",
       "      <td>0.933389</td>\n",
       "      <td>0.933337</td>\n",
       "      <td>0.933421</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>52.885771</td>\n",
       "      <td>0.686028</td>\n",
       "      <td>11.923641</td>\n",
       "      <td>0.403163</td>\n",
       "      <td>50000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>{'tfi__max_features': 50000, 'tfi__ngram_range...</td>\n",
       "      <td>0.937010</td>\n",
       "      <td>0.936912</td>\n",
       "      <td>0.935332</td>\n",
       "      <td>0.936418</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21.804713</td>\n",
       "      <td>2.162045</td>\n",
       "      <td>8.673323</td>\n",
       "      <td>0.246077</td>\n",
       "      <td>75000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfi__max_features': 75000, 'tfi__ngram_range...</td>\n",
       "      <td>0.935385</td>\n",
       "      <td>0.934596</td>\n",
       "      <td>0.934864</td>\n",
       "      <td>0.934948</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>15.715034</td>\n",
       "      <td>0.189433</td>\n",
       "      <td>6.660531</td>\n",
       "      <td>0.952548</td>\n",
       "      <td>75000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>{'tfi__max_features': 75000, 'tfi__ngram_range...</td>\n",
       "      <td>0.936419</td>\n",
       "      <td>0.936099</td>\n",
       "      <td>0.935431</td>\n",
       "      <td>0.935983</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>60.404871</td>\n",
       "      <td>0.494016</td>\n",
       "      <td>15.625234</td>\n",
       "      <td>0.290877</td>\n",
       "      <td>75000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfi__max_features': 75000, 'tfi__ngram_range...</td>\n",
       "      <td>0.933340</td>\n",
       "      <td>0.933562</td>\n",
       "      <td>0.933386</td>\n",
       "      <td>0.933429</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>50.222171</td>\n",
       "      <td>0.657336</td>\n",
       "      <td>11.366511</td>\n",
       "      <td>0.574766</td>\n",
       "      <td>75000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>{'tfi__max_features': 75000, 'tfi__ngram_range...</td>\n",
       "      <td>0.936739</td>\n",
       "      <td>0.937454</td>\n",
       "      <td>0.935628</td>\n",
       "      <td>0.936607</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>19.597433</td>\n",
       "      <td>0.947566</td>\n",
       "      <td>7.556967</td>\n",
       "      <td>0.044107</td>\n",
       "      <td>100000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfi__max_features': 100000, 'tfi__ngram_rang...</td>\n",
       "      <td>0.935212</td>\n",
       "      <td>0.934522</td>\n",
       "      <td>0.934741</td>\n",
       "      <td>0.934825</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>16.093993</td>\n",
       "      <td>1.641855</td>\n",
       "      <td>6.742985</td>\n",
       "      <td>0.191995</td>\n",
       "      <td>100000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>{'tfi__max_features': 100000, 'tfi__ngram_rang...</td>\n",
       "      <td>0.936468</td>\n",
       "      <td>0.936173</td>\n",
       "      <td>0.935160</td>\n",
       "      <td>0.935934</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>49.702607</td>\n",
       "      <td>0.858608</td>\n",
       "      <td>9.414363</td>\n",
       "      <td>0.692968</td>\n",
       "      <td>100000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tfi__max_features': 100000, 'tfi__ngram_rang...</td>\n",
       "      <td>0.933167</td>\n",
       "      <td>0.933734</td>\n",
       "      <td>0.933534</td>\n",
       "      <td>0.933478</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>40.562071</td>\n",
       "      <td>0.495644</td>\n",
       "      <td>8.507937</td>\n",
       "      <td>0.402373</td>\n",
       "      <td>100000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>{'tfi__max_features': 100000, 'tfi__ngram_rang...</td>\n",
       "      <td>0.936493</td>\n",
       "      <td>0.937134</td>\n",
       "      <td>0.935332</td>\n",
       "      <td>0.936320</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       20.139083      0.176619         8.409898        0.060415   \n",
       "1       18.161496      0.197442         7.322226        0.156035   \n",
       "2       63.464119      0.886825        15.866807        0.696200   \n",
       "3       52.885771      0.686028        11.923641        0.403163   \n",
       "4       21.804713      2.162045         8.673323        0.246077   \n",
       "5       15.715034      0.189433         6.660531        0.952548   \n",
       "6       60.404871      0.494016        15.625234        0.290877   \n",
       "7       50.222171      0.657336        11.366511        0.574766   \n",
       "8       19.597433      0.947566         7.556967        0.044107   \n",
       "9       16.093993      1.641855         6.742985        0.191995   \n",
       "10      49.702607      0.858608         9.414363        0.692968   \n",
       "11      40.562071      0.495644         8.507937        0.402373   \n",
       "\n",
       "   param_tfi__max_features param_tfi__ngram_range param_tfi__stop_words  \\\n",
       "0                    50000                 (1, 1)                  None   \n",
       "1                    50000                 (1, 1)               english   \n",
       "2                    50000                 (1, 2)                  None   \n",
       "3                    50000                 (1, 2)               english   \n",
       "4                    75000                 (1, 1)                  None   \n",
       "5                    75000                 (1, 1)               english   \n",
       "6                    75000                 (1, 2)                  None   \n",
       "7                    75000                 (1, 2)               english   \n",
       "8                   100000                 (1, 1)                  None   \n",
       "9                   100000                 (1, 1)               english   \n",
       "10                  100000                 (1, 2)                  None   \n",
       "11                  100000                 (1, 2)               english   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'tfi__max_features': 50000, 'tfi__ngram_range...           0.935508   \n",
       "1   {'tfi__max_features': 50000, 'tfi__ngram_range...           0.936542   \n",
       "2   {'tfi__max_features': 50000, 'tfi__ngram_range...           0.933537   \n",
       "3   {'tfi__max_features': 50000, 'tfi__ngram_range...           0.937010   \n",
       "4   {'tfi__max_features': 75000, 'tfi__ngram_range...           0.935385   \n",
       "5   {'tfi__max_features': 75000, 'tfi__ngram_range...           0.936419   \n",
       "6   {'tfi__max_features': 75000, 'tfi__ngram_range...           0.933340   \n",
       "7   {'tfi__max_features': 75000, 'tfi__ngram_range...           0.936739   \n",
       "8   {'tfi__max_features': 100000, 'tfi__ngram_rang...           0.935212   \n",
       "9   {'tfi__max_features': 100000, 'tfi__ngram_rang...           0.936468   \n",
       "10  {'tfi__max_features': 100000, 'tfi__ngram_rang...           0.933167   \n",
       "11  {'tfi__max_features': 100000, 'tfi__ngram_rang...           0.936493   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.934646           0.934864         0.935006        0.000366   \n",
       "1            0.936567           0.935603         0.936237        0.000449   \n",
       "2            0.933389           0.933337         0.933421        0.000085   \n",
       "3            0.936912           0.935332         0.936418        0.000769   \n",
       "4            0.934596           0.934864         0.934948        0.000327   \n",
       "5            0.936099           0.935431         0.935983        0.000412   \n",
       "6            0.933562           0.933386         0.933429        0.000096   \n",
       "7            0.937454           0.935628         0.936607        0.000751   \n",
       "8            0.934522           0.934741         0.934825        0.000288   \n",
       "9            0.936173           0.935160         0.935934        0.000560   \n",
       "10           0.933734           0.933534         0.933478        0.000235   \n",
       "11           0.937134           0.935332         0.936320        0.000746   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 7  \n",
       "1                 4  \n",
       "2                12  \n",
       "3                 2  \n",
       "4                 8  \n",
       "5                 5  \n",
       "6                11  \n",
       "7                 1  \n",
       "8                 9  \n",
       "9                 6  \n",
       "10               10  \n",
       "11                3  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params.to_csv('best_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying out my best model with 115 rows of new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_for_predictions = pd.read_csv('math_for_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = math_for_predictions['post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsTIFIlr_model.predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Whoâ€™s in Full Burn Out Mode? The burn out is real.'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline with Logistic Regression and Count Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for cv: 0.9355887666283462\n",
      "Best Parameters: {'cvect__max_features': 200000, 'cvect__ngram_range': (1, 2), 'cvect__stop_words': 'english'}\n",
      "Train score: 0.984455575628182\n",
      "Test score: 0.9389564960338966\n"
     ]
    }
   ],
   "source": [
    "pipeCVlr = Pipeline([           # Using pipeline with CountVectorizer and Logistic Regression\n",
    "    ('cvect', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeCVlr_params = {         # Setting the parameters \n",
    "               'cvect__max_features': [100_000, 200_000], \n",
    "               'cvect__stop_words': ['english'],\n",
    "               'cvect__ngram_range': [(1,2),(1,3)], \n",
    "              }\n",
    "\n",
    "# Using the GridSearchCV to find best parameters\n",
    "gsCVlr = GridSearchCV(pipeCVlr, # What is the model we want to fit?\n",
    "                  pipeCVlr_params, # What is the dictionary of hyperparameters?\n",
    "                  cv=3, verbose=1)\n",
    "\n",
    "gsCVlr.fit(X_train, y_train)   # Fitting the train data\n",
    "\n",
    "print(f'Best Score for cv: {gsCVlr.best_score_}')   # Printing best score for CV\n",
    "\n",
    "print(f'Best Parameters: {gsCVlr.best_params_}') # Checking best parameters for CV\n",
    "\n",
    "gsCVlr_model = gsCVlr.best_estimator_     # Setting our best model\n",
    "\n",
    "print(f'Train score: {gsCVlr_model.score(X_train, y_train)}')    # Scoring train data on our best model \n",
    "\n",
    "print(f'Test score: {gsCVlr_model.score(X_test, y_test)}')    # Scoring test data on our best model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline with Vote Classifier and Count Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 19.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score for cv: 0.9302841189029397\n",
      "Best Parameters: {'tfi__max_features': 100000, 'tfi__ngram_range': (1, 2), 'tfi__stop_words': 'english'}\n",
      "Train score: 0.9854327475775989\n",
      "Test score: 0.930211361284919\n"
     ]
    }
   ],
   "source": [
    "pipeTIFIet = Pipeline([           # Using pipeline with Vote Classifier\n",
    "    ('tfi', TfidfVectorizer(lowercase=False)),\n",
    "    ('vote', VotingClassifier([\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('MNB', MultinomialNB()),\n",
    "    ('et', ExtraTreesClassifier()),\n",
    "    ('rf', RandomForestClassifier())]))\n",
    "])\n",
    "\n",
    "pipeTIFIet_params = {         # Setting the parameters \n",
    "               'tfi__max_features': [75_000, 100_000], \n",
    "               'tfi__stop_words': ['english'],\n",
    "               'tfi__ngram_range': [(1,1),(1,2)], \n",
    "              }\n",
    "\n",
    "# Using the GridSearchCV to find best parameters\n",
    "gsTIFIet = GridSearchCV(pipeTIFIet, # What is the model we want to fit?\n",
    "                  pipeTIFIet_params, # What is the dictionary of hyperparameters?\n",
    "                  cv=3, verbose=1)\n",
    "\n",
    "gsTIFIet.fit(X_train, y_train)   # Fitting the train data\n",
    "\n",
    "print(f'Best Score for cv: {gsTIFIet.best_score_}')   # Printing best score for CV\n",
    "\n",
    "print(f'Best Parameters: {gsTIFIet.best_params_}') # Checking best parameters for CV\n",
    "\n",
    "gsTIFIet_model = gsTIFIet.best_estimator_     # Setting our best model\n",
    "\n",
    "print(f'Train score: {gsTIFIet_model.score(X_train, y_train)}')    # Scoring train data on our best model \n",
    "\n",
    "print(f'Test score: {gsTIFIet_model.score(X_test, y_test)}')    # Scoring test data on our best model \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
